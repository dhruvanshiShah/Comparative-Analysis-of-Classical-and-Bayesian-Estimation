{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSba81a0MNDz",
        "outputId": "72a205a6-7d7b-4923-ed8a-bf6e08611884"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n = 10\n",
            "MLE Estimate of Sigma:\n",
            "[[0.40342017 0.06384728]\n",
            " [0.06384728 1.47652275]]\n",
            "------------------------------\n",
            "n = 100\n",
            "MLE Estimate of Sigma:\n",
            "[[1.34248235 0.06127777]\n",
            " [0.06127777 1.84201507]]\n",
            "------------------------------\n",
            "n = 1000\n",
            "MLE Estimate of Sigma:\n",
            "[[0.98637743 0.04242716]\n",
            " [0.04242716 1.91840893]]\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# True covariance matrix\n",
        "true_Sigma = np.array([[1, 0], [0, 2]])\n",
        "\n",
        "# List of sample sizes\n",
        "sample_sizes = [10, 100, 1000]\n",
        "\n",
        "# For each n, generate samples and compute MLE estimate\n",
        "for n in sample_sizes:\n",
        "    # Step 1: Generate samples\n",
        "    y = np.random.multivariate_normal(mean=[0, 0], cov=true_Sigma, size=n)\n",
        "\n",
        "    # Step 2: Compute MLE of covariance\n",
        "    mle_Sigma = (y.T @ y) / n\n",
        "\n",
        "    print(f\"n = {n}\")\n",
        "    print(\"MLE Estimate of Sigma:\")\n",
        "    print(mle_Sigma)\n",
        "    print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def bayesian_cov_estimation(n, true_cov, delta_0, nu_0, seed=42):\n",
        "    np.random.seed(seed)\n",
        "    d = true_cov.shape[0]\n",
        "\n",
        "    # Generate n samples from N(0, true_cov)\n",
        "    y = np.random.multivariate_normal(mean=[0, 0], cov=true_cov, size=n)\n",
        "\n",
        "    # Calculate S = sum(y_i * y_i^T)\n",
        "    S = np.sum([np.outer(yi, yi) for yi in y], axis=0)\n",
        "\n",
        "    # Posterior parameters\n",
        "    nu_n = nu_0 + n\n",
        "    delta_n = delta_0 + S\n",
        "\n",
        "    # Posterior mean of inverse Wishart\n",
        "    cov_posterior_mean = delta_n / (nu_n - d - 1)\n",
        "\n",
        "    return cov_posterior_mean\n",
        "\n",
        "# Parameters\n",
        "true_cov = np.array([[1, 0], [0, 2]])\n",
        "delta_0 = np.array([[4, 0], [0, 5]])\n",
        "nu_0 = 5\n",
        "\n",
        "# Run for different n values\n",
        "for n in [10, 100, 1000]:\n",
        "    est = bayesian_cov_estimation(n, true_cov, delta_0, nu_0)\n",
        "    print(f\"n = {n}\")\n",
        "    print(\"Bayesian Estimate of Sigma:\")\n",
        "    print(np.round(est, 4))\n",
        "    print(\"-\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocaMxK61NCOa",
        "outputId": "7e19cace-613c-402c-fa65-0215703065d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n = 10\n",
            "Bayesian Estimate of Sigma:\n",
            "[[1.1303 0.4262]\n",
            " [0.4262 1.8391]]\n",
            "------------------------------\n",
            "n = 100\n",
            "Bayesian Estimate of Sigma:\n",
            "[[1.0087 0.0325]\n",
            " [0.0325 1.4986]]\n",
            "------------------------------\n",
            "n = 1000\n",
            "Bayesian Estimate of Sigma:\n",
            "[[1.0343 0.0062]\n",
            " [0.0062 1.851 ]]\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def generate_data(n, true_cov):\n",
        "    return np.random.multivariate_normal(mean=[0, 0], cov=true_cov, size=n)\n",
        "\n",
        "def bayesian_estimate_noninformative(data, nu0, Delta0):\n",
        "    n, d = data.shape\n",
        "    S = data.T @ data  # sufficient statistic\n",
        "    nu_n = nu0 + n\n",
        "    Delta_n = Delta0 + S\n",
        "    Sigma_est = Delta_n / (nu_n - d - 1)\n",
        "    return Sigma_est\n",
        "\n",
        "np.random.seed(42)\n",
        "true_cov = np.array([[1, 0], [0, 2]])\n",
        "Delta0_jeffreys = np.zeros((2, 2))\n",
        "n_values = [10, 100, 1000]\n",
        "\n",
        "# Results\n",
        "print(\"Results using Jeffreys prior (|Σ|^{-2}):\")\n",
        "for n in n_values:\n",
        "    data = generate_data(n, true_cov)\n",
        "    Sigma_jeff = bayesian_estimate_noninformative(data, nu0=3, Delta0=Delta0_jeffreys)\n",
        "    print(f\"n = {n}\")\n",
        "    print(\"Estimate of Sigma:\")\n",
        "    print(np.round(Sigma_jeff, 4))\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "print(\"\\nResults using Independence-Jeffreys prior (|Σ|^{-3/2}):\")\n",
        "for n in n_values:\n",
        "    data = generate_data(n, true_cov)\n",
        "    Sigma_indep_jeff = bayesian_estimate_noninformative(data, nu0=2.5, Delta0=Delta0_jeffreys)\n",
        "    print(f\"n = {n}\")\n",
        "    print(\"Estimate of Sigma:\")\n",
        "    print(np.round(Sigma_indep_jeff, 4))\n",
        "    print(\"-\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S58sD-GvP5Qx",
        "outputId": "7ddd92bf-c67c-414a-c5ed-2618c53fbf72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results using Jeffreys prior (|Σ|^{-2}):\n",
            "n = 10\n",
            "Estimate of Sigma:\n",
            "[[0.9564 0.5115]\n",
            " [0.5115 1.7069]]\n",
            "------------------------------\n",
            "n = 100\n",
            "Estimate of Sigma:\n",
            "[[1.0909 0.0677]\n",
            " [0.0677 1.4259]]\n",
            "------------------------------\n",
            "n = 1000\n",
            "Estimate of Sigma:\n",
            "[[ 1.0031 -0.0091]\n",
            " [-0.0091  1.9243]]\n",
            "------------------------------\n",
            "\n",
            "Results using Independence-Jeffreys prior (|Σ|^{-3/2}):\n",
            "n = 10\n",
            "Estimate of Sigma:\n",
            "[[ 0.7274 -1.0378]\n",
            " [-1.0378  2.6497]]\n",
            "------------------------------\n",
            "n = 100\n",
            "Estimate of Sigma:\n",
            "[[0.8904 0.1437]\n",
            " [0.1437 1.8624]]\n",
            "------------------------------\n",
            "n = 1000\n",
            "Estimate of Sigma:\n",
            "[[1.0381 0.0243]\n",
            " [0.0243 2.0275]]\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import invwishart\n",
        "\n",
        "def generate_data(n, true_cov):\n",
        "    return np.random.multivariate_normal(mean=[0, 0], cov=true_cov, size=n)\n",
        "\n",
        "def log_likelihood(Sigma, data):\n",
        "    n, d = data.shape\n",
        "    sign, logdet = np.linalg.slogdet(Sigma)\n",
        "    if sign <= 0:\n",
        "        return -np.inf  # Invalid covariance matrix\n",
        "\n",
        "    inv_sigma = np.linalg.inv(Sigma)\n",
        "    quad_form = np.sum([y.T @ inv_sigma @ y for y in data])\n",
        "    return (-n / 2) * logdet - 0.5 * quad_form\n",
        "\n",
        "def monte_carlo_bayes(data, nu0, delta0, m):\n",
        "    d = delta0.shape[0]\n",
        "    samples = invwishart.rvs(df=nu0, scale=delta0, size=m)\n",
        "    if m == 1:\n",
        "        samples = [samples]\n",
        "\n",
        "    log_ws = np.array([log_likelihood(Sigma, data) for Sigma in samples])\n",
        "\n",
        "    # log-sum-exp trick for numerical stability\n",
        "    max_log_w = np.max(log_ws)\n",
        "    stable_ws = np.exp(log_ws - max_log_w)\n",
        "    weights = stable_ws / np.sum(stable_ws)\n",
        "\n",
        "    # Weighted average of the samples\n",
        "    weighted_sum = sum(w * S for w, S in zip(weights, samples))\n",
        "    return weighted_sum\n",
        "\n",
        "# Parameters\n",
        "true_cov = np.array([[1, 0], [0, 2]])\n",
        "n_values = [10, 100, 1000]\n",
        "m_values = [10**3, 10**4, 10**5]\n",
        "\n",
        "# Priors\n",
        "priors = {\n",
        "    \"Prior A\": {\"nu0\": 5, \"delta0\": np.array([[4, 0], [0, 5]])},\n",
        "    \"Prior B\": {\"nu0\": 5, \"delta0\": np.array([[2, 0], [0, 4]])}\n",
        "}\n",
        "\n",
        "# Running the simulations\n",
        "results = {}\n",
        "\n",
        "for prior_name, prior_params in priors.items():\n",
        "    results[prior_name] = {}\n",
        "    for n in n_values:\n",
        "        data = generate_data(n, true_cov)\n",
        "        results[prior_name][n] = {}\n",
        "        for m in m_values:\n",
        "            print(f\"Running {prior_name}, n={n}, m={m}...\")\n",
        "            A_est = monte_carlo_bayes(data, prior_params[\"nu0\"], prior_params[\"delta0\"], m)\n",
        "            results[prior_name][n][m] = A_est\n",
        "\n",
        "# Display results\n",
        "for prior_name in results:\n",
        "    print(f\"\\nResults using {prior_name}:\")\n",
        "    for n in results[prior_name]:\n",
        "        print(f\"n = {n}\")\n",
        "        for m in results[prior_name][n]:\n",
        "            print(f\"  m = {m}:\")\n",
        "            print(results[prior_name][n][m])\n",
        "        print(\"-\" * 40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtITSWnlSGKc",
        "outputId": "98594339-a9c3-414a-8a37-0ce2c69a2237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Prior A, n=10, m=1000...\n",
            "Running Prior A, n=10, m=10000...\n",
            "Running Prior A, n=10, m=100000...\n",
            "Running Prior A, n=100, m=1000...\n",
            "Running Prior A, n=100, m=10000...\n",
            "Running Prior A, n=100, m=100000...\n",
            "Running Prior A, n=1000, m=1000...\n",
            "Running Prior A, n=1000, m=10000...\n",
            "Running Prior A, n=1000, m=100000...\n",
            "Running Prior B, n=10, m=1000...\n",
            "Running Prior B, n=10, m=10000...\n",
            "Running Prior B, n=10, m=100000...\n",
            "Running Prior B, n=100, m=1000...\n",
            "Running Prior B, n=100, m=10000...\n",
            "Running Prior B, n=100, m=100000...\n",
            "Running Prior B, n=1000, m=1000...\n",
            "Running Prior B, n=1000, m=10000...\n",
            "Running Prior B, n=1000, m=100000...\n",
            "\n",
            "Results using Prior A:\n",
            "n = 10\n",
            "  m = 1000:\n",
            "[[1.18309727 0.01104977]\n",
            " [0.01104977 1.57848646]]\n",
            "  m = 10000:\n",
            "[[1.17908785 0.02445063]\n",
            " [0.02445063 1.55894717]]\n",
            "  m = 100000:\n",
            "[[1.18884333 0.02559059]\n",
            " [0.02559059 1.57416565]]\n",
            "----------------------------------------\n",
            "n = 100\n",
            "  m = 1000:\n",
            "[[ 1.13657998 -0.01227224]\n",
            " [-0.01227224  1.97607822]]\n",
            "  m = 10000:\n",
            "[[1.06569515 0.01550449]\n",
            " [0.01550449 1.96991847]]\n",
            "  m = 100000:\n",
            "[[1.07612338 0.03059126]\n",
            " [0.03059126 1.96217531]]\n",
            "----------------------------------------\n",
            "n = 1000\n",
            "  m = 1000:\n",
            "[[ 1.00822073 -0.02592435]\n",
            " [-0.02592435  1.95137904]]\n",
            "  m = 10000:\n",
            "[[1.06022182 0.00708737]\n",
            " [0.00708737 1.94963376]]\n",
            "  m = 100000:\n",
            "[[1.03922693 0.04032406]\n",
            " [0.04032406 1.94533647]]\n",
            "----------------------------------------\n",
            "\n",
            "Results using Prior B:\n",
            "n = 10\n",
            "  m = 1000:\n",
            "[[0.71230919 0.10116566]\n",
            " [0.10116566 1.25994777]]\n",
            "  m = 10000:\n",
            "[[0.72393444 0.08933828]\n",
            " [0.08933828 1.25555296]]\n",
            "  m = 100000:\n",
            "[[0.7227419  0.08369866]\n",
            " [0.08369866 1.26850353]]\n",
            "----------------------------------------\n",
            "n = 100\n",
            "  m = 1000:\n",
            "[[ 0.9721348  -0.09380005]\n",
            " [-0.09380005  2.09437137]]\n",
            "  m = 10000:\n",
            "[[ 0.85803461 -0.11864673]\n",
            " [-0.11864673  2.16895543]]\n",
            "  m = 100000:\n",
            "[[ 0.86077509 -0.10683491]\n",
            " [-0.10683491  2.17811716]]\n",
            "----------------------------------------\n",
            "n = 1000\n",
            "  m = 1000:\n",
            "[[1.03235251e+00 1.10237756e-03]\n",
            " [1.10237756e-03 1.79695070e+00]]\n",
            "  m = 10000:\n",
            "[[ 1.0589603  -0.0214134 ]\n",
            " [-0.0214134   1.90491305]]\n",
            "  m = 100000:\n",
            "[[ 1.01794991 -0.0023265 ]\n",
            " [-0.0023265   1.89599637]]\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " import numpy as np\n",
        "from scipy.stats import invwishart, invgamma\n",
        "\n",
        "# --- Configuration ---\n",
        "np.random.seed(42)\n",
        "n = 100  # number of data points\n",
        "d = 2    # dimension\n",
        "nu = 3\n",
        "A1, A2 = 0.05, 0.05\n",
        "iterations = 1000\n",
        "\n",
        "# True covariance\n",
        "Sigma_true = np.array([[1, 0], [0, 2]])\n",
        "\n",
        "# Generate data\n",
        "Y = np.random.multivariate_normal(mean=[0, 0], cov=Sigma_true, size=n)\n",
        "\n",
        "# Initialize a1, a2, Sigma\n",
        "a = np.array([1.0, 1.0])\n",
        "Sigma = np.eye(d)\n",
        "\n",
        "# For storing Sigma samples\n",
        "Sigma_samples = []\n",
        "\n",
        "# Precompute Y^T Y (sum of y_i y_i^T)\n",
        "YTY = Y.T @ Y\n",
        "\n",
        "# --- Gibbs Sampling ---\n",
        "for _ in range(iterations):\n",
        "    # Step 1: Sample Sigma | Y, a\n",
        "    scale_matrix = 2 * nu * np.diag(1 / a) + YTY\n",
        "    df = nu + d + n - 1\n",
        "    Sigma = invwishart.rvs(df=df, scale=scale_matrix)\n",
        "\n",
        "    # Step 2: Sample a_k | Y, Sigma\n",
        "    Sigma_inv = np.linalg.inv(Sigma)\n",
        "    for k in range(d):\n",
        "        shape = (nu + n) / 2\n",
        "        rate = nu * Sigma_inv[k, k] + 1 / (A1**2 if k == 0 else A2**2)\n",
        "        a[k] = invgamma.rvs(a=shape, scale=rate)\n",
        "\n",
        "    Sigma_samples.append(Sigma)\n",
        "\n",
        "# Final estimate: posterior mean\n",
        "Sigma_est = np.mean(Sigma_samples, axis=0)\n",
        "\n",
        "print(\"Posterior covariance estimate after 1000 Gibbs iterations:\")\n",
        "print(np.round(Sigma_est, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6V5GMq9mbmA8",
        "outputId": "a927008b-bf60-40ff-e1a7-475bcdd5d376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Posterior covariance estimate after 1000 Gibbs iterations:\n",
            "[[0.9833 0.0363]\n",
            " [0.0363 1.4816]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " import numpy as np\n",
        "from scipy.stats import invwishart, invgamma\n",
        "\n",
        "# --- Configuration ---\n",
        "np.random.seed(42)\n",
        "n = 100  # number of data points\n",
        "d = 2    # dimension\n",
        "nu = 3\n",
        "A1, A2 = 0.05, 0.05\n",
        "iterations = 10000\n",
        "\n",
        "# True covariance\n",
        "Sigma_true = np.array([[1, 0], [0, 2]])\n",
        "\n",
        "# Generate data\n",
        "Y = np.random.multivariate_normal(mean=[0, 0], cov=Sigma_true, size=n)\n",
        "\n",
        "# Initialize a1, a2, Sigma\n",
        "a = np.array([1.0, 1.0])\n",
        "Sigma = np.eye(d)\n",
        "\n",
        "# For storing Sigma samples\n",
        "Sigma_samples = []\n",
        "\n",
        "# Precompute Y^T Y (sum of y_i y_i^T)\n",
        "YTY = Y.T @ Y\n",
        "\n",
        "# --- Gibbs Sampling ---\n",
        "for _ in range(iterations):\n",
        "    # Step 1: Sample Sigma | Y, a\n",
        "    scale_matrix = 2 * nu * np.diag(1 / a) + YTY\n",
        "    df = nu + d + n - 1\n",
        "    Sigma = invwishart.rvs(df=df, scale=scale_matrix)\n",
        "\n",
        "    # Step 2: Sample a_k | Y, Sigma\n",
        "    Sigma_inv = np.linalg.inv(Sigma)\n",
        "    for k in range(d):\n",
        "        shape = (nu + n) / 2\n",
        "        rate = nu * Sigma_inv[k, k] + 1 / (A1**2 if k == 0 else A2**2)\n",
        "        a[k] = invgamma.rvs(a=shape, scale=rate)\n",
        "\n",
        "    Sigma_samples.append(Sigma)\n",
        "\n",
        "# Final estimate: posterior mean\n",
        "Sigma_est = np.mean(Sigma_samples, axis=0)\n",
        "\n",
        "print(\"Posterior covariance estimate after 1000 Gibbs iterations:\")\n",
        "print(np.round(Sigma_est, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qm5HHVjIcYr9",
        "outputId": "65dec464-e41b-4410-e97b-8e5ccf1c3eca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Posterior covariance estimate after 1000 Gibbs iterations:\n",
            "[[0.9869 0.0338]\n",
            " [0.0338 1.4719]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.special import gammaln\n",
        "from scipy.optimize import minimize_scalar\n",
        "from scipy.stats import invwishart\n",
        "\n",
        "# Sample generation (assumed)\n",
        "np.random.seed(42)\n",
        "true_cov = np.array([[1, 0], [0, 2]])\n",
        "n = 1000\n",
        "d = 2\n",
        "y = np.random.multivariate_normal(np.zeros(d), true_cov, size=n)\n",
        "\n",
        "# Sample covariance sum\n",
        "S = sum(np.outer(yi, yi) for yi in y)\n",
        "\n",
        "# Empirical Bayes: Define log marginal likelihood (unnormalized)\n",
        "def log_marginal_likelihood(nu, S, n, d):\n",
        "    term1 = nu * np.log((nu + n) / nu)\n",
        "    term2 = n * np.log((nu + n) / n)\n",
        "\n",
        "    def log_multigamma(a, p):\n",
        "        return (p * (p - 1) / 4) * np.log(np.pi) + np.sum(gammaln(a - (np.arange(p) / 2)))\n",
        "\n",
        "    term3 = log_multigamma(nu / 2, d)\n",
        "    term4 = log_multigamma((nu + n) / 2, d)\n",
        "\n",
        "    return -(term1 + term2 + term3 - term4)\n",
        "\n",
        "# Optimize ν using scalar minimization\n",
        "res = minimize_scalar(lambda nu: -log_marginal_likelihood(nu, S, n, d),\n",
        "                      bounds=(d + 2, 500), method='bounded')\n",
        "nu_opt = res.x\n",
        "\n",
        "# Compute ∆opt\n",
        "Delta_opt = (nu_opt / n) * S\n",
        "\n",
        "# Compute posterior mean of Inverse Wishart\n",
        "posterior_df = nu_opt + n\n",
        "posterior_scale = Delta_opt + S\n",
        "posterior_mean = posterior_scale / (posterior_df - d - 1)\n",
        "\n",
        "# Print results\n",
        "print(\"Optimal ν:\", nu_opt)\n",
        "print(\"Posterior covariance estimate (Empirical Bayes):\")\n",
        "print(np.round(posterior_mean, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N99oe7FGcjLW",
        "outputId": "832dfad7-b610-4f13-ec0e-01b284787ea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal ν: 499.9999867106493\n",
            "Posterior covariance estimate (Empirical Bayes):\n",
            "[[1.0344 0.0063]\n",
            " [0.0063 1.8534]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7lWfNRl-0vf0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}